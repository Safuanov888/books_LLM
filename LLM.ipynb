{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTVewrmuGbpH"
   },
   "source": [
    "# Цель: сгенерировать текст стилем автора, используя предобученную LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZjMzo2BuRnU_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import re\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Используется GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "### ДЛЯ КОРРЕКТНОЙ РАБОТЫ МОДЕЛЕЙ ###\n",
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"D:/HuggingFace\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = os.environ[\"HF_HOME\"]\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = os.environ[\"HF_HOME\"] \n",
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "tokenizer_t5 = T5Tokenizer.from_pretrained(\"cointegrated/rut5-base-paraphraser\", force_download=True, local_files_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Доп. библиотеки "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Spire.Doc\n",
      "  Using cached Spire.Doc-13.1.0-py3-none-win_amd64.whl.metadata (14 kB)\n",
      "Collecting transformers==4.21.0\n",
      "  Using cached transformers-4.21.0-py3-none-any.whl.metadata (81 kB)\n",
      "Requirement already satisfied: tokenizers==0.12.1 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.1)\n",
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting bert_score\n",
      "  Using cached bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.21.0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.21.0) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.21.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.21.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.21.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.21.0) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.21.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.21.0) (4.67.1)\n",
      "Requirement already satisfied: plum-dispatch==1.7.4 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Spire.Doc) (1.7.4)\n",
      "Requirement already satisfied: click in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sacremoses) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sacremoses) (1.2.0)\n",
      "Requirement already satisfied: dill in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from evaluate) (1.5.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from evaluate) (3.5.0)\n",
      "Collecting multiprocess (from evaluate)\n",
      "  Using cached multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bert_score) (2.2.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bert_score) (3.6.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (19.0.1)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.8.6)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0 (from transformers==4.21.0)\n",
      "  Using cached huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.21.0) (4.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers==4.21.0) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers==4.21.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers==4.21.0) (2023.11.17)\n",
      "Requirement already satisfied: sympy in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.0.0->bert_score) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.0.0->bert_score) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.0.0->bert_score) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers==4.21.0) (0.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->bert_score) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->bert_score) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->bert_score) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->bert_score) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->bert_score) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->bert_score) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\турбо\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n",
      "Using cached transformers-4.21.0-py3-none-any.whl (4.7 MB)\n",
      "Using cached Spire.Doc-13.1.0-py3-none-win_amd64.whl (28.1 MB)\n",
      "Using cached evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Using cached bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "Using cached datasets-3.4.1-py3-none-any.whl (487 kB)\n",
      "Using cached huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Installing collected packages: Spire.Doc, multiprocess, huggingface-hub, transformers, datasets, bert_score, evaluate\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.21.4\n",
      "    Uninstalling huggingface-hub-0.21.4:\n",
      "      Successfully uninstalled huggingface-hub-0.21.4\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.39.0\n",
      "    Uninstalling transformers-4.39.0:\n",
      "      Successfully uninstalled transformers-4.39.0\n",
      "Successfully installed Spire.Doc-13.1.0 bert_score-0.3.13 datasets-3.4.1 evaluate-0.4.3 huggingface-hub-0.29.3 multiprocess-0.70.16 transformers-4.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install Spire.Doc transformers==4.21.0 tokenizers==0.12.1 -U sacremoses evaluate bert_score datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NADRw4-lX66M"
   },
   "source": [
    "### Считываем все файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eqvgdD6cbeMi",
    "outputId": "1ea0f603-28c2-46f3-a676-eb6b03e6985a"
   },
   "outputs": [],
   "source": [
    "#drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwiMjFeUSzwk"
   },
   "source": [
    "# Чтение текстов с файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# Kaggle\n",
    "# books = pathlib.Path(\"/kaggle/input/bolshakov-data/new_data\")\n",
    "\n",
    "# Jupyter \n",
    "books = pathlib.Path(\"D:/ПРОГА/Проектики/Github/books_LLM/new_data\")\n",
    "\n",
    "files_to_process = []\n",
    "for book in books.iterdir():\n",
    "    files_to_process.append(str(book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\ПРОГА\\\\Проектики\\\\Github\\\\books_LLM\\\\new_data\\\\2.RTF'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_to_process[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Просмотр и обработка текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-Mos55_CSgsk"
   },
   "outputs": [],
   "source": [
    "from spire.doc import *\n",
    "from spire.doc.common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(text, max_tokens=512):\n",
    "    \"\"\"\n",
    "    Разбивает текст на чанки по max_tokens токенов, сохраняя границы предложений.\n",
    "    \"\"\"\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text)  \n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for sent in sentences:\n",
    "        sent_tokens = tokenizer_t5.tokenize(sent)\n",
    "        sent_token_count = len(sent_tokens)\n",
    "\n",
    "        if sent_token_count > max_tokens:\n",
    "            for i in range(0, sent_token_count, max_tokens):\n",
    "                chunk = tokenizer_t5.convert_tokens_to_string(sent_tokens[i:i+max_tokens])\n",
    "                chunks.append(chunk)\n",
    "            continue\n",
    "\n",
    "        if current_length + sent_token_count > max_tokens:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "\n",
    "        current_chunk.append(sent)\n",
    "        current_length += sent_token_count\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc_and_get_chunks(file):\n",
    "    doc = Document()\n",
    "    doc.LoadFromFile(file)\n",
    "    text = doc.GetText()\n",
    "    text = text.replace('Evaluation Warning: The document was created with Spire.Doc for Python.', '')\n",
    "    text = text.replace('\\t', '')\n",
    "    clean_text = re.sub(\n",
    "        r'\\d+\\r\\n|\\r\\n|\\x0c|УДК.*|ББК.*|Издание.*|– М.*|ISBN.*|©.*',\n",
    "        '\\n', \n",
    "        text\n",
    "    )\n",
    "    final_chunks = []\n",
    "    paragraphs = [p.strip() for p in clean_text.split('\\n') if p.strip()]\n",
    "    for paragraph in paragraphs:\n",
    "        if len(paragraph) < 100:\n",
    "            continue\n",
    "        chunks = split_into_chunks(paragraph)\n",
    "        final_chunks.extend(chunks)\n",
    "    return final_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "textes = clean_doc_and_get_chunks(files_to_process[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "8QobKc2WamVc",
    "outputId": "d8296df2-d412-4bff-9181-af97014cf9cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Часть 1, токенов: 180\n",
      "Летопись рисует нам Владимира Мономаха идеалом русского князя: он мирит враждующих; свято соблюдает крестное целование; подает пример набожности, правосудия, гостеприимства и превосходит всех воинским...\n",
      "\n",
      "Часть 2, токенов: 192\n",
      "По его собственному объяснению, дед (Ярослав Мудрый) назвал его Владимиром, а отец с матерью — Мономахом, в честь деда по матери – греческого царя. Сохранилось известие, что император Алексей Комнин п...\n",
      "\n",
      "Часть 3, токенов: 93\n",
      "Христианское воззрение на власть развивалось Русской Церковью последовательнее, чем в Византии, именно потому, что Православная государственность перешла к нам не в процессе своего развития, а уже впо...\n",
      "\n",
      "Часть 4, токенов: 64\n",
      "Андрей Боголюбский, внук Владимира Мономаха, которого историки иногда называют первым русским самодержцем, вопреки общему мнению князей, заявил, что власть – в нем самом, а не в земле и не в князьях....\n",
      "\n",
      "Часть 5, токенов: 332\n",
      "Иоанн III – потомок первого собирателя Руси Ивана Калиты, сын и преемник Василия Темного, который соединил почти все земли Северо-Восточной Руси в одно Московское государство. Окончательно свергнув по...\n",
      "\n",
      "Часть 6, токенов: 501\n",
      "Принцип первородства, который не всегда был основой наследования отчины, со времени Иоанна III становится обязательным. Начиная с этой эпохи старший сын уже при жизни отца становится соправителем посл...\n",
      "\n",
      "Часть 7, токенов: 50\n",
      "Царь-самодержец выражает не волю народа, а его православное миросозерцание и, следовательно, олицетворяет ту Высшую силу, которая создала этот идеал....\n",
      "\n",
      "Часть 8, токенов: 214\n",
      "Хорошо известно выражение: “Москва — Третий Рим”. Однако что же следует понимать под “Римом”? После принятия Константином Великим христианства как государственной религии в 312 году Константинополь ст...\n",
      "\n",
      "Часть 9, токенов: 126\n",
      "Софья Палеолог не оправдала надежд папы римского. Оказавшись женой русского Великого князя, она не только отказалась от рим\u001fской унии, в традициях которой была воспитана, но и стала усердной сторонниц...\n",
      "\n",
      "Часть 10, токенов: 95\n",
      "Порой доходило до нелепостей. Легенда о призвании варяжских князей, вероятно, под влиянием Софьи Палеолог, пошла еще дальше. Варяжских предков начали производить от Пруса, якобы родственника или даже ...\n",
      "\n",
      "Часть 11, токенов: 234\n",
      "Опускаем драматические события, связанные с коронованием и печальной участью внука Иоанна III от первого брака царевича Димитрия, закончившиеся победой Софьи Фоминичны и переходом власти к ее сыну Вас...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(textes):\n",
    "    if i <= 10:\n",
    "        print(f\"Часть {i+1}, токенов: {len(tokenizer_t5.tokenize(chunk))}\")\n",
    "        print(chunk[:200] + \"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U2W9wWt6u7J"
   },
   "source": [
    "# Генерирование тестовой выборки с помощью перефразеров\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Th9umlekbSzl"
   },
   "source": [
    "## Функция переплексии - метрика, которая вычисляет схожесть текстов по смыслу, применяя модель Сбера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xsFn_Q7iSi0V"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "BHNKRPazSi6c"
   },
   "outputs": [],
   "source": [
    "mname = 'ai-forever/rugpt3small_based_on_gpt2'\n",
    "gpt_tokenizer = AutoTokenizer.from_pretrained(mname)\n",
    "gpt_model = AutoModelForCausalLM.from_pretrained(mname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt2_ppl_corpus(test_textes, aggregate=True, sep='\\n', max_length=1024):\n",
    "    lls, weights = [], []\n",
    "    for text in tqdm(test_textes):\n",
    "        encodings = gpt_tokenizer(f'{sep}{text}{sep}', return_tensors='pt', padding=True, truncation=True, max_length=max_length)\n",
    "        input_ids = encodings.input_ids.to(gpt_model.device)\n",
    "        target_ids = input_ids.clone()\n",
    "\n",
    "        w = max(0, len(input_ids[0]) - 1)\n",
    "        if w > 0:\n",
    "            with torch.no_grad():\n",
    "                output = gpt_model(input_ids, labels=target_ids)\n",
    "                likelihood = output[0]\n",
    "                ll = likelihood.item()\n",
    "        else:\n",
    "            ll = 0\n",
    "        lls.append(ll)\n",
    "        weights.append(w)\n",
    "    likelihoods, weights = np.array(lls), np.array(weights)\n",
    "    if aggregate:\n",
    "        return sum(likelihoods * weights) / sum(weights)\n",
    "    return likelihoods, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f244c37973d4e0383ab6ff6c505f06c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "bertscore = evaluate.load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Валидация работы предобученной T5 на задаче перефразирования "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T19:35:24.814781Z",
     "iopub.status.busy": "2025-03-17T19:35:24.814482Z",
     "iopub.status.idle": "2025-03-17T19:35:40.289128Z",
     "shell.execute_reply": "2025-03-17T19:35:40.288445Z",
     "shell.execute_reply.started": "2025-03-17T19:35:24.814758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed475d221e84762a82249c7b11ac664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/724 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa7d1945a31456e98ced67d42f89e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/932M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"cointegrated/rut5-base-paraphraser\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T19:38:52.537945Z",
     "iopub.status.busy": "2025-03-17T19:38:52.537640Z",
     "iopub.status.idle": "2025-03-17T19:38:52.543848Z",
     "shell.execute_reply": "2025-03-17T19:38:52.543143Z",
     "shell.execute_reply.started": "2025-03-17T19:38:52.537921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer_t5.tokenize(final_chunks[11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T20:18:44.946621Z",
     "iopub.status.busy": "2025-03-17T20:18:44.946227Z",
     "iopub.status.idle": "2025-03-17T20:18:44.951818Z",
     "shell.execute_reply": "2025-03-17T20:18:44.950916Z",
     "shell.execute_reply.started": "2025-03-17T20:18:44.946589Z"
    }
   },
   "outputs": [],
   "source": [
    "text = final_chunks[11]\n",
    "input_ids = tokenizer_t5.encode(\"paraphrase: \" + text, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,           # ← Включить сэмплирование\n",
    "    temperature=1,          # Случайность (0.5-1.2)\n",
    "    top_k=50,                 # Ограничить выбор топ-50 токенами\n",
    "    top_p=0.95,               # Nucleus sampling\n",
    "    max_length=181+50,\n",
    "    min_length=181,\n",
    "    no_repeat_ngram_size=3\n",
    ")\n",
    "decoded = tokenizer_t5.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T19:46:33.577142Z",
     "iopub.status.busy": "2025-03-17T19:46:33.576842Z",
     "iopub.status.idle": "2025-03-17T19:46:33.582274Z",
     "shell.execute_reply": "2025-03-17T19:46:33.581537Z",
     "shell.execute_reply.started": "2025-03-17T19:46:33.577114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Таким образом, в результате правильно проведенного стимулирования контактов у людей, занимающихся управлениями, должно формироваться желание действовать не только в интересах личного, но и более широких объединений граждан (например, в акционерном обществе или корпорации), то есть появляется реальная возможность для оптимального согласования интересов своих и общественных организаций. Основная сила связей: отдельно взятое руководство и контролирует посторонние внешние объекты, которые должны работать против серьезных интересов и заинтересованных, иначе говоря. Очередь - значит, было преданное государствам. <b> Относительно темы и представлений на сайте является: <b] <p> <p</p> > <p]> [p>'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T19:46:33.584151Z",
     "iopub.status.busy": "2025-03-17T19:46:33.583714Z",
     "iopub.status.idle": "2025-03-17T19:46:33.595903Z",
     "shell.execute_reply": "2025-03-17T19:46:33.595186Z",
     "shell.execute_reply.started": "2025-03-17T19:46:33.584128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Правильная организация обратных связей должна приводить к модификации вторичных интересов, их коррекции в сторону общественно полезных, а не наоборот, как это происходит зачастую сейчас. Героем нашего времени стал не труженик, ученый, летчик или разведчик, а вор, обманщик, казнокрад и карточный жулик. С введением же правильно организованных стимулирующих обратных связей у человека, участвующего в организации управления, появляется желание действовать не только в личных интересах, но и в интересах более широких объединений граждан (например, в акционерном обществе или корпорации), т.е. появляется реальная возможность оптимального согласования своих и общественных интересов.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chunks[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T19:41:28.961947Z",
     "iopub.status.busy": "2025-03-17T19:41:28.961656Z",
     "iopub.status.idle": "2025-03-17T19:41:38.467498Z",
     "shell.execute_reply": "2025-03-17T19:41:38.466472Z",
     "shell.execute_reply.started": "2025-03-17T19:41:28.961925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508fbc40b232467c9e38c90162563cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/796 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение переплекcии: 6.361718785554211\n"
     ]
    }
   ],
   "source": [
    "print(f'Значение переплекcии: {get_gpt2_ppl_corpus(decoded)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сбор маленького датасета "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T20:42:29.651122Z",
     "iopub.status.busy": "2025-03-17T20:42:29.650677Z",
     "iopub.status.idle": "2025-03-17T20:42:29.657096Z",
     "shell.execute_reply": "2025-03-17T20:42:29.656159Z",
     "shell.execute_reply.started": "2025-03-17T20:42:29.651081Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_text(file):\n",
    "    samples = []\n",
    "    for t in file:\n",
    "        min_len = len(tokenizer_t5.tokenize(t))\n",
    "        input_ids = tokenizer_t5.encode(\"paraphrase: \" + t, return_tensors=\"pt\").to(device)\n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            do_sample=True,           # ← Включить сэмплирование\n",
    "            temperature=1,          # Случайность (0.5-1.2)\n",
    "            top_k=50,                 # Ограничить выбор топ-50 токенами\n",
    "            top_p=0.95,               # Nucleus sampling\n",
    "            max_length=min_len+50,\n",
    "            min_length=min_len,\n",
    "            no_repeat_ngram_size=3\n",
    "        )\n",
    "        decoded = tokenizer_t5.decode(outputs[0], skip_special_tokens=True)\n",
    "        samples.append(''.join(decoded))\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:05:02.817662Z",
     "iopub.status.busy": "2025-03-17T21:05:02.817191Z",
     "iopub.status.idle": "2025-03-17T21:05:03.431795Z",
     "shell.execute_reply": "2025-03-17T21:05:03.431053Z",
     "shell.execute_reply.started": "2025-03-17T21:05:02.817624Z"
    }
   },
   "outputs": [],
   "source": [
    "file1 = clean_doc_and_get_chunks(files_to_process[0])\n",
    "file2 = clean_doc_and_get_chunks(files_to_process[1])\n",
    "file3 = clean_doc_and_get_chunks(files_to_process[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:09:17.739107Z",
     "iopub.status.busy": "2025-03-17T21:09:17.738771Z",
     "iopub.status.idle": "2025-03-17T21:27:42.667685Z",
     "shell.execute_reply": "2025-03-17T21:27:42.666583Z",
     "shell.execute_reply.started": "2025-03-17T21:09:17.739081Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_first_file = generate_text(file1)\n",
    "train_data_second_file = generate_text(file2)\n",
    "train_data_third_file = generate_text(file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:32:17.674152Z",
     "iopub.status.busy": "2025-03-17T21:32:17.673834Z",
     "iopub.status.idle": "2025-03-17T21:32:17.679250Z",
     "shell.execute_reply": "2025-03-17T21:32:17.678307Z",
     "shell.execute_reply.started": "2025-03-17T21:32:17.674126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_first_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:32:49.963581Z",
     "iopub.status.busy": "2025-03-17T21:32:49.963215Z",
     "iopub.status.idle": "2025-03-17T21:32:49.967971Z",
     "shell.execute_reply": "2025-03-17T21:32:49.967035Z",
     "shell.execute_reply.started": "2025-03-17T21:32:49.963551Z"
    }
   },
   "outputs": [],
   "source": [
    "finetuning_data = pd.DataFrame({'train': train_data_first_file + train_data_second_file + train_data_third_file, \n",
    "                                'target': file1 + file2 + file3\n",
    "                               }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:32:51.860870Z",
     "iopub.status.busy": "2025-03-17T21:32:51.860583Z",
     "iopub.status.idle": "2025-03-17T21:32:51.865776Z",
     "shell.execute_reply": "2025-03-17T21:32:51.865056Z",
     "shell.execute_reply.started": "2025-03-17T21:32:51.860849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324, 2)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuning_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T21:42:07.000141Z",
     "iopub.status.busy": "2025-03-17T21:42:06.999865Z",
     "iopub.status.idle": "2025-03-17T21:42:07.016336Z",
     "shell.execute_reply": "2025-03-17T21:42:07.015731Z",
     "shell.execute_reply.started": "2025-03-17T21:42:07.000120Z"
    }
   },
   "outputs": [],
   "source": [
    "finetuning_data.to_csv('small_dataset.csv', sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle\n",
    "#finetuning_data = pd.read_csv('/kaggle/input/bolshakov-small-dataset/small_dataset.csv')\n",
    "\n",
    "# Jupyter\n",
    "finetuning_data = pd.read_csv('D:/ПРОГА/Проектики/Github/books_LLM/small_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Вопрос о деятельности социополитических систем...</td>\n",
       "      <td>В функционировании социально-политических сист...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- Подробнее: Существует понятие управления свя...</td>\n",
       "      <td>Кратко напомним, что такое управление с обратн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Например, применение стимулирующей обратной св...</td>\n",
       "      <td>Стимулирующие обратные связи делят на положите...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- Общая форма организации для всех систем прос...</td>\n",
       "      <td>Общий для всех систем способ их организации пр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Для связи, при которой предусмотрена система, ...</td>\n",
       "      <td>Обратные связи могут осуществляться как с помо...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               train  \\\n",
       "0  Вопрос о деятельности социополитических систем...   \n",
       "1  - Подробнее: Существует понятие управления свя...   \n",
       "2  Например, применение стимулирующей обратной св...   \n",
       "3  - Общая форма организации для всех систем прос...   \n",
       "4  Для связи, при которой предусмотрена система, ...   \n",
       "\n",
       "                                              target  \n",
       "0  В функционировании социально-политических сист...  \n",
       "1  Кратко напомним, что такое управление с обратн...  \n",
       "2  Стимулирующие обратные связи делят на положите...  \n",
       "3  Общий для всех систем способ их организации пр...  \n",
       "4  Обратные связи могут осуществляться как с помо...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuning_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T20:14:43.899779Z",
     "iopub.status.busy": "2025-03-18T20:14:43.899471Z",
     "iopub.status.idle": "2025-03-18T20:14:49.017672Z",
     "shell.execute_reply": "2025-03-18T20:14:49.016970Z",
     "shell.execute_reply.started": "2025-03-18T20:14:43.899758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6e2f6d513d42aca7b8eb0717275bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя переплексия в маленьком датасете: 4.5989\n"
     ]
    }
   ],
   "source": [
    "print(f'Средняя переплексия в маленьком датасете: {get_gpt2_ppl_corpus(small_data[\"train\"]):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средний BLEU в маленьком датасете: 0.1651\n"
     ]
    }
   ],
   "source": [
    "all_metrics = []\n",
    "for i in range(len(finetuning_data)):\n",
    "    hypotheses = finetuning_data['train'][i].split()\n",
    "    references = finetuning_data['target'][i].split()\n",
    "    all_metrics.append(sentence_bleu([references], hypotheses))\n",
    "print(f'Средний BLEU в маленьком датасете: {np.mean(all_metrics):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05abdca8e00c4e7396b3b56a647a28a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ad30e6546b454da6869ccfa42b66c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средний BERTScore в маленьком датасете: 0.8155\n"
     ]
    }
   ],
   "source": [
    "print(f'Средний BERTScore в маленьком датасете: {(np.mean(bertscore.compute(predictions=finetuning_data[\"train\"], references=finetuning_data[\"target\"], lang=\"ru\")[\"f1\"])):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дообучение T5 на маленьком датасете"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных и токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_data['train'] = \"paraphrase: \" + finetuning_data['train']\n",
    "dataset = Dataset.from_pandas(finetuning_data).train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de703002a8b8498995797f52a41c7174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/291 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b3e37d7b5e477aabd6b167b87dc899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_length = 512\n",
    "\n",
    "def preprocess(examples):\n",
    "    inputs = tokenizer_t5(\n",
    "        examples['train'],\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        padding='max_length'\n",
    "    )\n",
    "\n",
    "    targets = tokenizer_t5(\n",
    "        examples['target'],\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        padding='max_length'\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": inputs.input_ids,\n",
    "        \"attention_mask\": inputs.attention_mask,\n",
    "        \"labels\": targets.input_ids\n",
    "    }\n",
    "tokenized_dataset = dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DatasetDict.align_labels_with_mapping of DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['train', 'target', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 291\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['train', 'target', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 33\n",
       "    })\n",
       "})>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset.align_labels_with_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6884836,
     "sourceId": 11051247,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6899070,
     "sourceId": 11071011,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
